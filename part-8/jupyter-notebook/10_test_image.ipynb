{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d42219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "from utils import test, train_keep_best \n",
    "from mydatasets import get_dataset\n",
    "from mymodels import MLP, CNN\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9689fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c620e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1285297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main python function\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # parse the command line arguments\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "    parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                        help='number of epochs to train (default: 10)')\n",
    "    \n",
    "    # argument for training only\n",
    "    parser.add_argument('--train', action='store_true', default=False,\n",
    "                        help='train the model')\n",
    "    \n",
    "    # argument for testing only\n",
    "    parser.add_argument('--test', action='store_true', default=False,\n",
    "                        help='test the model')\n",
    "    \n",
    "    # argument to print the model\n",
    "    parser.add_argument('--print', action='store_true', default=False,\n",
    "                        help='print the model')\n",
    "    \n",
    "    # argument to print the model and trainable parameters\n",
    "    parser.add_argument('--info', action='store_true', default=False,\n",
    "                        help='print the model info')\n",
    "    \n",
    "    # argument to name the trained model\n",
    "    parser.add_argument('--name', type=str, default='mnist.pt',\n",
    "                        help='name of the trained model')\n",
    "\n",
    "    # argument to decide the dataset\n",
    "    parser.add_argument('--dataset', type=str, default='mnist',\n",
    "                        help='dataset to use: mnist or fashion_mnist')\n",
    "    \n",
    "    # argument to decide the model type\n",
    "    parser.add_argument('--model', type=str, default='mlp',\n",
    "                        help='model to use: mlp or cnn')\n",
    "    \n",
    "    # argument to decide the batch size\n",
    "    parser.add_argument('--batch_size', type=int, default=64,\n",
    "                        help='batch size for training and testing')\n",
    "    \n",
    "    # argument to decide the learning rate\n",
    "    parser.add_argument('--lr', type=float, default=0.01,\n",
    "                        help='learning rate for training')\n",
    "    \n",
    "    # argument to resume training\n",
    "    parser.add_argument('--resume', action='store_true', default=False,\n",
    "                        help='learning rate for training')\n",
    "    \n",
    "    # argument to get image input from command line to classify\n",
    "    parser.add_argument('--image', type=str, default=None,\n",
    "                        help='image file to classify')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8a940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #     args = parser.parse_args()\n",
    "    # This is a notebook. So you have to put the arguments hard-coded      \n",
    "    args = parser.parse_args(\"--image ./figures/car2.jpg --dataset cifar10 --name cifar10_cnn.pt --model cnn\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484be9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # decide which dataset to use\n",
    "    if args.dataset == 'mnist':\n",
    "        input_size = 28\n",
    "        channels = 1\n",
    "        output_size = 10\n",
    "    elif args.dataset == 'fashion_mnist':\n",
    "        input_size = 28\n",
    "        channels = 1\n",
    "        output_size = 10\n",
    "    elif args.dataset == 'cifar10':\n",
    "        input_size = 32\n",
    "        channels = 3\n",
    "        output_size = 10\n",
    "    elif args.dataset == 'cifar100':\n",
    "        input_size = 32\n",
    "        channels = 3\n",
    "        output_size = 100\n",
    "    else:\n",
    "        print('Invalid dataset')\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd8f03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # define the model and configure the number of layers\n",
    "    if args.model == 'mlp':\n",
    "        hidden_size = 512\n",
    "        model = MLP(input_size, channels, hidden_size, output_size).to(device)\n",
    "    elif args.model == 'cnn':\n",
    "        if args.dataset == 'mnist' or args.dataset == 'fashion_mnist':\n",
    "            model = CNN_mnist(input_size, channels, output_size).to(device)\n",
    "        elif args.dataset == 'cifar10' or args.dataset == 'cifar100':\n",
    "            model = CNN(input_size, channels, output_size).to(device)\n",
    "    else:\n",
    "        print('Invalid model')\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3003f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Define the optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "    # Define the loss function\n",
    "    criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3735455",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # train the model\n",
    "    if args.train:\n",
    "        train_loader, test_loader = get_dataset(args.dataset, args.batch_size) \n",
    "        acc_now = 0.0\n",
    "        for epoch in range(1, args.epochs + 1):\n",
    "            acc_now = train_keep_best(epoch, model, args.model, device, train_loader, test_loader, optimizer, criterion, input_size, channels, args.name, acc_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23111234",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if args.test:\n",
    "        train_loader, test_loader = get_dataset(args.dataset, args.batch_size) \n",
    "    # load the model as checkpoint and see multiple information\n",
    "        checkpoint = torch.load(args.name)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "        loss = checkpoint['loss']\n",
    "        acc = checkpoint['acc']\n",
    "        print('Model trained for', epoch, 'epochs with accuracy', acc, 'and loss', loss)\n",
    "        test(model, args.model, device, test_loader, criterion, input_size, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad84f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if args.resume:\n",
    "        train_loader, test_loader = get_dataset(args.dataset, args.batch_size) \n",
    "        # load the model as checkpoint and see multiple information\n",
    "        checkpoint = torch.load(args.name)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "        loss = checkpoint['loss']\n",
    "        acc = checkpoint['acc']\n",
    "        print('Model trained for', epoch, 'epochs with accuracy', acc, 'and loss', loss)\n",
    "        print('Resuming training...')\n",
    "        for epoch in range(epoch+1, epoch + args.epochs):\n",
    "            acc = train_keep_best(epoch, model, args.model, device, train_loader, test_loader, optimizer, criterion, input_size, channels, args.name, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0b888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # print the model\n",
    "    if args.print:\n",
    "        print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ce5e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # print the model info\n",
    "    if args.info:\n",
    "        print(model)\n",
    "        print('Model Info')\n",
    "        for name, param in model.named_parameters():\n",
    "            print(name, param.shape)\n",
    "        print('Trainable parameters:\\n',sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6203d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if args.image:\n",
    "        # classes of cifar10\n",
    "        classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "        # load the model as checkpoint and see multiple information\n",
    "        checkpoint = torch.load(args.name)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "        loss = checkpoint['loss']\n",
    "        acc = checkpoint['acc']\n",
    "        print('Model trained for', epoch, 'epochs with accuracy', acc, 'and loss', loss)\n",
    "        print('This the image you want to classify:')\n",
    "        # show the image\n",
    "        img = Image.open(args.image)\n",
    "        plt.imshow(img)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc511c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # transform the image\n",
    "        transform = transforms.Compose([transforms.Resize((input_size, input_size)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0.5,), (0.5,))])\n",
    "        \n",
    "        img = transform(img)\n",
    "        # show the transformed image\n",
    "        plt.imshow(img[0], cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d47e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # add a dimension to the image\n",
    "        img = img.unsqueeze(0)\n",
    "\n",
    "        # classify the image\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(img)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            print('The image is classified as', pred.item(), 'which is', classes[pred.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de74a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # write with red in the middle on the original image the predicted class\n",
    "            img = Image.open(args.image)\n",
    "            plt.imshow(img)\n",
    "            plt.text(0.5, 0.5, classes[pred.item()], color='red', fontsize=20, horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
