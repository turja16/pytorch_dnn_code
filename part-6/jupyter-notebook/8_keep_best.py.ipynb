{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494e2eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "from utils import test, train_keep_best \n",
    "from mydatasets import load_mnist, load_fashion_mnist, load_cifar10, load_cifar100\n",
    "from mymodels import MLP, CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4c1d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9bbeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main python function\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # parse the command line arguments\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "    parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                        help='number of epochs to train (default: 10)')\n",
    "    \n",
    "    # argument for training only\n",
    "    parser.add_argument('--train', action='store_true', default=False,\n",
    "                        help='train the model')\n",
    "    \n",
    "    # argument for testing only\n",
    "    parser.add_argument('--test', action='store_true', default=False,\n",
    "                        help='test the model')\n",
    "    \n",
    "    # argument to print the model\n",
    "    parser.add_argument('--print', action='store_true', default=False,\n",
    "                        help='print the model')\n",
    "    \n",
    "    # argument to print the model and trainable parameters\n",
    "    parser.add_argument('--info', action='store_true', default=False,\n",
    "                        help='print the model info')\n",
    "    \n",
    "    # argument to name the trained model\n",
    "    parser.add_argument('--name', type=str, default='mnist.pt',\n",
    "                        help='name of the trained model')\n",
    "\n",
    "    # argument to decide the dataset\n",
    "    parser.add_argument('--dataset', type=str, default='mnist',\n",
    "                        help='dataset to use: mnist or fashion_mnist')\n",
    "    \n",
    "    # argument to decide the model type\n",
    "    parser.add_argument('--model', type=str, default='mlp',\n",
    "                        help='model to use: mlp or cnn')\n",
    "    \n",
    "    # argument to decide the batch size\n",
    "    parser.add_argument('--batch_size', type=int, default=64,\n",
    "                        help='batch size for training and testing')\n",
    "    \n",
    "    # argument to decide the learning rate\n",
    "    parser.add_argument('--lr', type=float, default=0.01,\n",
    "                        help='learning rate for training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdabf0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #     args = parser.parse_args()\n",
    "    # This is a notebook. So you have to put the arguments hard-coded      \n",
    "    args = parser.parse_args(\"--train --epochs 2 --dataset cifar100 --name cifar100_cnn.pt --batch_size 128 --model cnn\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc6376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # decide which dataset to use\n",
    "    if args.dataset == 'mnist':\n",
    "        train_loader, test_loader = load_mnist(batch_size=args.batch_size)\n",
    "        input_size = 28\n",
    "        channels = 1\n",
    "        output_size = 10\n",
    "    elif args.dataset == 'fashion_mnist':\n",
    "        train_loader, test_loader = load_fashion_mnist(batch_size=args.batch_size)\n",
    "        input_size = 28\n",
    "        channels = 1\n",
    "        output_size = 10\n",
    "    elif args.dataset == 'cifar10':\n",
    "        train_loader, test_loader = load_cifar10(batch_size=args.batch_size)\n",
    "        input_size = 32\n",
    "        channels = 3\n",
    "        output_size = 10\n",
    "    elif args.dataset == 'cifar100':\n",
    "        train_loader, test_loader = load_cifar100(batch_size=args.batch_size)\n",
    "        input_size = 32\n",
    "        channels = 3\n",
    "        output_size = 100\n",
    "    else:\n",
    "        print('Invalid dataset')\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f10342",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # define the model and configure the number of layers\n",
    "    if args.model == 'mlp':\n",
    "        hidden_size = 512\n",
    "        model = MLP(input_size, channels, hidden_size, output_size).to(device)\n",
    "    elif args.model == 'cnn':\n",
    "        if args.dataset == 'mnist' or args.dataset == 'fashion_mnist':\n",
    "            model = CNN_mnist(input_size, channels, output_size).to(device)\n",
    "        elif args.dataset == 'cifar10' or args.dataset == 'cifar100':\n",
    "            model = CNN(input_size, channels, output_size).to(device)\n",
    "    else:\n",
    "        print('Invalid model')\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0d709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Define the optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "    # Define the loss function\n",
    "    criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce22f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # train the model\n",
    "    if args.train:\n",
    "        acc_now = 0.0\n",
    "        for epoch in range(1, args.epochs + 1):\n",
    "            acc_now = train_keep_best(epoch, model, args.model, device, train_loader, test_loader, optimizer, criterion, input_size, channels, args.name, acc_now)\n",
    "\n",
    "    # test the model\n",
    "    if args.test:\n",
    "        model.load_state_dict(torch.load(args.name))\n",
    "        test(model, args.model, device, test_loader, criterion, input_size, channels)\n",
    "        \n",
    "    # print the model\n",
    "    if args.print:\n",
    "        print(model)\n",
    "\n",
    "    # print the model info\n",
    "    if args.info:\n",
    "        print(model)\n",
    "        print('Model Info')\n",
    "        for name, param in model.named_parameters():\n",
    "            print(name, param.shape)\n",
    "        print('Trainable parameters:\\n',sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
